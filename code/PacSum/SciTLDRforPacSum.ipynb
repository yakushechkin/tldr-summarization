{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Dmitrii Iakushechkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import errno\n",
    "import json\n",
    "import jsonlines\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertSciTLDRforPacSum(path,task,mode):\n",
    "    '''\n",
    "    Args:\n",
    "        task: ['A', 'AIC', 'FullText']\n",
    "        mode: ['train','test','dev']\n",
    "    '''\n",
    "    \n",
    "    tldr_list = []\n",
    "    with jsonlines.open(os.path.join(path,'SciTLDR-{}'.format(task),'{}.jsonl'.format(mode))) as reader:\n",
    "        print('1. {} dataset is loaded'.format(mode))\n",
    "        counter = 0\n",
    "        counter_tldrs = 0\n",
    "        for obj in reader:\n",
    "            counter +=1\n",
    "            obj_pacsum = dict()\n",
    "            obj_pacsum['article'] = obj['source']\n",
    "            \n",
    "            if isinstance(obj['target'], list):\n",
    "                for item in obj['target']:\n",
    "                    counter_tldrs += 1\n",
    "                    obj_pacsum['abstract'] = [item]\n",
    "                    s = json.dumps(obj_pacsum).encode('UTF-8')\n",
    "                    tldr_list.append(s)\n",
    "            elif isinstance(obj['target'], str):\n",
    "                    counter_tldrs += 1\n",
    "                    obj_pacsum['abstract'] = [obj['target']]\n",
    "                    s = json.dumps(obj_pacsum).encode('UTF-8')\n",
    "                    tldr_list.append(s)\n",
    "            else:\n",
    "                print('Unknown type of target data.')\n",
    "\n",
    "        print('2. The {} dataset has {} articles'.format(mode, counter))\n",
    "        print('3. The {} dataset has {} TLDRs'.format(mode, counter_tldrs))\n",
    "    arr = np.array(tldr_list)\n",
    "    print('Array is ready for saving!')\n",
    "    return arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveSciTLDRforPacSum(path,arr,task,mode):\n",
    "    '''\n",
    "    Function for saving an array with bytes as a h5df file.\n",
    "    Args:\n",
    "        task: ['A', 'AIC', 'FullText']\n",
    "        mode: ['train','test','dev']\n",
    "    '''\n",
    "    path = os.path.join(path,'SciTLDR-{}'.format(task),'forPacSum')\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError as err:\n",
    "        if err.errno == errno.EEXIST:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    with h5py.File(os.path.join(path,'tldr_{}.h5df'.format(mode)), 'w') as f:\n",
    "        f.create_dataset(\"dataset\", data=arr,dtype = h5py.string_dtype(encoding='ascii'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SciTLDRforPacSum(path,task,mode):\n",
    "    arr = convertSciTLDRforPacSum(path,task,mode)\n",
    "    saveSciTLDRforPacSum(path,arr,task,mode)\n",
    "    print('The {} dataset for {} task is saved. \\n'.format(mode,task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the path is necessary\n",
    "scitldr_path = os.path.join(os.getcwd(), '../../scitldr/SciTLDR-Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. test dataset is loaded\n",
      "2. The test dataset has 618 articles\n",
      "3. The test dataset has 1324 TLDRs\n",
      "Array is ready for saving!\n",
      "The test dataset for A task is saved. \n",
      "\n",
      "1. train dataset is loaded\n",
      "2. The train dataset has 1992 articles\n",
      "3. The train dataset has 1992 TLDRs\n",
      "Array is ready for saving!\n",
      "The train dataset for A task is saved. \n",
      "\n",
      "1. dev dataset is loaded\n",
      "2. The dev dataset has 619 articles\n",
      "3. The dev dataset has 619 TLDRs\n",
      "Array is ready for saving!\n",
      "The dev dataset for A task is saved. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "SciTLDRforPacSum(scitldr_path,'A','test')\n",
    "SciTLDRforPacSum(scitldr_path,'A','train')\n",
    "SciTLDRforPacSum(scitldr_path,'A','dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
